# 4.5.2 /api/v1/ai/credit_risk_explain
+> Nota: traducción generada automáticamente desde el inglés; revisar antes de publicar.


**Local explainability for one borrower**

### Propósito
Post a mixed batch of labelled & un-labelled applicants and receive model quality, per-applicant PDs and explainable SHAP drivers.

---

### Headers `X-Customer-Api-Id`, `X-Secret`

```yml
POST https://api.abintel.ai/api/v1/ai/credit_risk_explain
headers:
X-Customer-Api-Id: <uuid>
X-Secret: <secret>
Content-Type: application/json
```


---

## Why this route exists

| **Need**                                                    | **What the endpoint delivers**                                                                              |
|------------------------------------------------------------ |------------------------------------------------------------------------------------------------------------ |
| Credit officer asks “Why did the model flag this customer?” | Per-feature contribution scores (`explanation{}`) and a plain-English sentence (`interpretation`).          |
| Regulators demand local explanations                        | A local surrogate (LIME) or Tree-SHAP explainer is fit on the fly from the mini training sample you supply. |
| Want to double-check a borderline decision                  | Full PD for the single borrower (probability) is returned along with the drivers.                           |

---

## Request payload reference

| **Path**                  | **Type**       | **Required** | **Notes**                                                                 |
|---------------------------|----------------|--------------|---------------------------------------------------------------------------|
| `applicant.id`            | string         | ✔︎           | Copied back in errors/logs.                                               |
| `applicant.features`      | object         | ✔︎           | Same free-form schema used in training/scoring routes.                    |
| `training_sample[]`       | array          | ✔︎           | ≥ 50 rows with label so the explainer can learn local decision boundaries.|
| ↳ `label`                 | 0 / 1          | ✔︎           | 1 = default / charge-off, 0 = paid back.                                  |

 **Tip** Reuse a random slice of the last batch you posted to `/api/credit_risk_score` to keep payloads light.

---

### Solicitud

```json
{
  "applicant": {
    "id": "app-XYZ",
    "features": {
      "income": 42000,
      "age": 29,
      "country": "BR",
      "late_payments": 2
    }
  },
  "training_sample": [
    { "id": "s-001", "features": { "income": 55000, "age": 34, "country": "BR", "late_payments": 0 }, "label": 0 },
    ...
    { "id": "s-050", "features": { "income": 18500, "age": 24, "country": "BR", "late_payments": 8 }, "label": 1 }
  ]
}
```

---

### Respuesta

```yml
{
  "probability": 0.0,
  "explanation": {
    "income": 0.0,
    "age": -3.469446951953614e-18,
    "late payments": 0.0,
    "country BR": 2.6020852139652106e-18,
    "country CA": 4.336808689942018e-19,
    "country NG": 1.734723475976807e-18,
    "country UK": 3.7947076036992655e-19,
    "country US": 2.3852447794681098e-18
  },
  "interpretation": "PD 0.0 % ⇒ LOW risk.  income +0.0 ↓ risk; age -0.0 ↓ risk; late payments +0.0 ↓ risk; country BR +0.0 ↑ risk; country CA +0.0 ↑ risk; country NG +0.0 ↑ risk; country UK +0.0 ↑ risk; country US +0.0 ↑ risk"
}
```

Magnitudes are additive log-odds (SHAP) or local linear weights (LIME) depending on the data mix; signs show direction.

---

### Under the hood

* Encoding – same one-hot rules as the main scoring service.

* Local neighbourhood – explainer samples ≈ 5,000 synthetic points around the applicant (kernel density).

* Surrogate model – linear/LASSO (LIME) or Tree-SHAP depending on feature types.

* PD computation – uses your last deployed champion model (if any) or fits a quick Logistic Regression on the supplied sample.

* Interpretation string – converts top contributions into a human-readable sentence.

---

### Flujo de Trabajo Típico

1. Score batch with `/api/credit_risk_score;` keep IDs with PD ≥ threshold.

2. Explain flagged IDs individually with `/api/credit_risk_explain` and embed the plain-English sentence in your credit-committee UI.

3. Archive both the surrogate coefficients and original PD for audit.

---

