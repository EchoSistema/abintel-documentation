# 4.2.2 /api/v1/ai/propensity_respond_campaign
+> Nota: tradução gerada automaticamente a partir do inglês; revise antes de publicar.


---

### Purpose – Will They Engage With This Campaign?

Forecast the individual likelihood that a customer will open, click, or purchase from a specific marketing campaign. Ideal for:

* Audience trimming to protect deliverability

* Discount allocation (e.g., full coupon only to top deciles)

* Predictive hold-out tests & incremental-lift measurement

---

### Headers `X-Customer-Api-Id`, `X-Secret`

```yaml
POST  https://api-prod.abintel.ai/api/v1/ai/propensity_respond_campaign
Headers
  X-Customer-Api-Id: <uuid>
  X-Secret:          <secret>
  Content-Type:      application/json
```

---

### Esquema do Corpo da Requisição

## Required Fields

| **Key**       | **Type / Range** | **Required?** | **Meaning**                         | **Typical Derivation**      |
| ------------- | ---------------- | ------------- | ----------------------------------- | --------------------------- |
| `campaign_id` | string           | yes           | ID or slug of the outbound campaign | e.g., `"Spring-Promo-2025"` |
| `customers`   | array<object>    | yes           | Rows to score (or train + score)    | From CDP or ESP export      |

---

### Customer Object Fields

| **Field**       | **Type** | **Required?** | **Business Meaning**               |
| --------------- | -------- | ------------- | ---------------------------------- |
| `customer_id`   | string   | yes           | Primary key (CRM ID)               |
| `features`      | object   | yes           | Numeric/categorical features       |
| `label_respond` | 0 / 1    | optional      | Ground truth if customer responded |

---

### Starter Feature Kit

| **Feature**          | **What it Captures**        | **Example SQL / Source**         |
| -------------------- | --------------------------- | -------------------------------- |
| `email_click_rate`   | Historical email engagement | clicks / sends over last 90 days |
| `sms_opt_in`         | SMS subscription flag       | From ESP opt-in table            |
| `purchases_last_90d` | Recent transaction count    | `COUNT(DISTINCT order_id)`       |

---

### What the Service Does

1. Label Check: Requires ≥ 20 of both label_respond = 0 and label_respond = 1.

2. AutoML: Runs Logistic Regression, XGBoost, Random Forest, CatBoost with 5-fold CV.

3. Scoring: Outputs calibrated P(respond = 1).

4. Tier Mapping (default):

* Very High ≥ 0.9

* High ≥ 0.7

* Medium ≥ 0.4

* Low ≥ 0.2

* Very Low < 0.2

5. Interpretation: Tier-specific explanations in plain English.

---

### Example 1 – Too Few Labels

## Requisição

```json
{
  "campaign_id": "Spring-Promo-2025",
  "customers": [
    {
      "customer_id": "C-2001",
      "features": {
        "email_click_rate": 0.22,
        "sms_opt_in": 1,
        "purchases_last_90d": 3
      },
      "label_respond": 0
    }
  ]
}
```

---

## Resposta

```json
{
  "predictions": [
    {
      "customer_id": "C-2001",
      "probability": null,
      "propensity_tier": "Very Low",
      "interpretation": "Very low propensity – deprioritise in current cycle."
    }
  ],
  "model_info": {
    "note": "not enough labelled rows to train (need ≥20 & both classes)"
  }
}
```

---

### Example 2 – Full Model Training & Scoring

Assume 10,000 rows passed, with 2,000 historical responders (`label_respond = 1`).

## Response Snippet

```json
{
  "predictions": [
    {
      "customer_id": "C-6155",
      "probability": 0.77,
      "propensity_tier": "High",
      "interpretation": "High propensity – include in main send."
    },
    {
      "customer_id": "C-9342",
      "probability": 0.12,
      "propensity_tier": "Very Low",
      "interpretation": "Very low propensity – suppress or cheaper channel."
    }
  ],
  "model_info": {
    "best_algorithm": "XGBoost",
    "roc_auc": 0.812,
    "feature_importance": ["email_click_rate", "purchases_last_90d", "sms_opt_in"],
    "train_rows": 9000,
    "test_rows": 1000
  }
}
```

---

### Response Field Guide

| **Path**                    | **Type**     | **Meaning**                          | **Usage**                        |
| --------------------------- | ------------ | ------------------------------------ | -------------------------------- |
| `predictions[].probability` | float / null | Response probability                 | Score thresholding at 0.7 or 0.4 |
| `propensity_tier`           | enum         | Engagement likelihood tier           | Segment filters in ESP or CRM    |
| `interpretation`            | string       | Readable explanation                 | Sales or support rep copy        |
| `best_algorithm`            | string       | AutoML model used                    | For reproducibility              |
| `roc_auc`                   | float        | Hold-out performance (AUC)           | Model evaluation metric          |
| `note`                      | string       | Shown when model training is skipped | Alert data team if shown         |

---

### Commercial Playbooks

| **Use Case**         | **Action**                                      | **Lift / ROI**                        |
| -------------------- | ----------------------------------------------- | ------------------------------------- |
| Email deliverability | Send only to Medium–Very High tiers             | +8 pp open-rate, –40% spam complaints |
| Discount cost        | Give full discount to High/Very High only       | –18% promo cost, +5% revenue          |
| SMS vs Push          | SMS = High tiers, Push = Medium, Suppress = Low | –27% messaging cost, same revenue     |
| A/B testing          | Hold out 10% of High tier for true uplift       | Clean incremental sales measurement   |

---

###  Data Engineering Best Practices

1. **Label window** – mark `label_respond` = 1 if customer opened OR clicked OR transacted within 7 days of campaign send (customisable).

2. **Feature freshness** – refresh behavioural features nightly; stale email-click rates hurt performance fast.

3. **Cold-start campaigns** – for brand-new `campaign_id` with zero labels, warm-start with a global engagement model (road-map endpoint `propensity_engage_any`).

4. **Feature parity** – keep the same feature set between training and inference to avoid schema drift.

---

### FAQ

| **Q**                                         | **A**                                                       |
| --------------------------------------------- | ----------------------------------------------------------- |
| Can I train once and score later?             | Yes, models are cached for 30 days.                         |
| Can I score for click vs purchase separately? | Multi-class model support planned for Q1 2026.              |
| How many customers per call?                  | 100,000 rows or 20MB; bulk async in roadmap.                |
| PII / GDPR safe?                              | Yes – only `customer_id` is required. Use hashes if needed. |

---

### Próximo Passo

Send High and Very High IDs into your ESP, prioritize based on score, and maximize ROAS while minimizing list fatigue.

Let me know if you'd like me to format the next endpoint `/propensity_upgrade_plan` in the same style.

---

